{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.11",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "sourceId": 11474913,
     "sourceType": "datasetVersion",
     "datasetId": 7191644
    }
   ],
   "dockerImageVersionId": 31012,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": true
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": "!pip install comet_ml -q timm fastai albumentations",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-08-03T14:33:13.746056Z",
     "iopub.execute_input": "2025-08-03T14:33:13.746261Z",
     "iopub.status.idle": "2025-08-03T14:34:29.914066Z",
     "shell.execute_reply.started": "2025-08-03T14:33:13.746243Z",
     "shell.execute_reply": "2025-08-03T14:34:29.913151Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m729.6/729.6 kB\u001B[0m \u001B[31m11.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\n\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.2/1.2 MB\u001B[0m \u001B[31m36.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m3.5/3.5 MB\u001B[0m \u001B[31m88.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m:00:01\u001B[0m\n\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m363.4/363.4 MB\u001B[0m \u001B[31m4.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m0:00:01\u001B[0m00:01\u001B[0m\n\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m664.8/664.8 MB\u001B[0m \u001B[31m2.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m0:00:01\u001B[0m00:01\u001B[0m\n\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m211.5/211.5 MB\u001B[0m \u001B[31m2.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m0:00:01\u001B[0m00:01\u001B[0m\n\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m56.3/56.3 MB\u001B[0m \u001B[31m30.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m:00:01\u001B[0m00:01\u001B[0m\n\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m127.9/127.9 MB\u001B[0m \u001B[31m13.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m:00:01\u001B[0m00:01\u001B[0m\n\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m207.5/207.5 MB\u001B[0m \u001B[31m8.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m0:00:01\u001B[0m00:01\u001B[0m\n\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m21.1/21.1 MB\u001B[0m \u001B[31m71.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m:00:01\u001B[0m00:01\u001B[0m\n\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m144.8/144.8 kB\u001B[0m \u001B[31m10.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25h\u001B[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\npylibcugraph-cu12 24.12.0 requires pylibraft-cu12==24.12.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 24.12.0 requires rmm-cu12==24.12.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001B[0m\u001B[31m\n\u001B[0m",
     "output_type": "stream"
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "import random\n",
    "import torch\n",
    "import timm\n",
    "import albumentations as alb\n",
    "from fastai.vision.all import *\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "import gc\n",
    "import comet_ml\n",
    "\n",
    "COMET_API_KEY = \"My_comet\"\n",
    "COMET_PROJECT_NAME = \"classification-for-landslide-detection-ensamble-pytorch\"\n",
    "\n",
    "DATA_ROOT = \"/kaggle/input/slideandseekclasificationlandslidedetectiondataset\"\n",
    "TRAIN_CSV = f\"{DATA_ROOT}/Train.csv\"\n",
    "TEST_CSV = f\"{DATA_ROOT}/Test.csv\"\n",
    "TRAIN_NPY_PATH = f\"{DATA_ROOT}/train_data/train_data\"\n",
    "TEST_NPY_PATH = f\"{DATA_ROOT}/test_data/test_data\"\n",
    "\n",
    "class Config:\n",
    "    n_splits = 3\n",
    "    seed = 42\n",
    "    image_size = 196\n",
    "    model_name = \"eva_large_patch14_196.in22k_ft_in22k_in1k\"\n",
    "    batch_size = 16\n",
    "    epochs = 10 # used only 10 epochs, but using more likely will get better f1\n",
    "    tta = 4\n",
    "    num_classes = 2\n",
    "    IMAGE_COMBINATIONS = [\n",
    "        ['red', 'green', 'blue'],\n",
    "        ['nir', 'red', 'green'],\n",
    "        ['nir', 'green', 'blue'],\n",
    "        ['nir', 'red', 'blue'],\n",
    "    ] # Used only 4 combinations and didn't used SAR channels, probably using them will get better f1\n",
    "    PARENT_SAVE_PATH = \"/kaggle/working/landslide_composite_images/\"\n",
    "\n",
    "CFG = Config()\n",
    "\n",
    "def random_seed(seed_value, use_cuda):\n",
    "    np.random.seed(seed_value)\n",
    "    torch.manual_seed(seed_value)\n",
    "    random.seed(seed_value)\n",
    "    if use_cuda:\n",
    "        torch.cuda.manual_seed(seed_value)\n",
    "        torch.cuda.manual_seed_all(seed_value)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "\n",
    "random_seed(CFG.seed, True)\n",
    "\n",
    "os.makedirs(CFG.PARENT_SAVE_PATH, exist_ok=True)\n",
    "\n",
    "\n",
    "train_df = pd.read_csv(TRAIN_CSV)\n",
    "test_df = pd.read_csv(TEST_CSV)\n",
    "\n",
    "train_df['numpy_path'] = train_df['ID'].apply(lambda x: TRAIN_NPY_PATH + f\"/{x}.npy\")\n",
    "test_df['numpy_path'] = test_df['ID'].apply(lambda x: TEST_NPY_PATH + f\"/{x}.npy\")\n",
    "\n",
    "label_counts = train_df['label'].value_counts()\n",
    "print(\"Distribution of labels in training set:\\n\", label_counts)\n",
    "\n",
    "drop_ids = [\"ID_Z29R76\"]\n",
    "train_df = train_df[~train_df['ID'].isin(drop_ids)].reset_index(drop=True)\n",
    "\n",
    "BAND_NAMES = [\n",
    "    \"red\", \"green\", \"blue\", \"nir\",\n",
    "    \"desc_vv\", \"desc_vh\", \"desc_diff_vv\", \"desc_diff_vh\",\n",
    "    \"asc_vv\", \"asc_vh\", \"asc_diff_vv\", \"asc_diff_vh\"\n",
    "]\n",
    "def generate_and_save_composite_images(df, combinations, parent_save_path, data_type='train', image_format = 'png'):\n",
    "    assert image_format in ['png', 'jpg'], \"Only png or jpg images are supported\"\n",
    "\n",
    "    for _, row in tqdm(df.iterrows(), total=df.shape[0], desc=f\"Generating {data_type} images\"):\n",
    "        tile = np.load(row['numpy_path'])\n",
    "        assert tile.shape[-1] == len(BAND_NAMES), f\"Expected {len(BAND_NAMES)} bands, got {tile.shape[-1]} bands\"\n",
    "        image_id = row['ID']\n",
    "\n",
    "        for combo in combinations:\n",
    "            try:\n",
    "                indices = [BAND_NAMES.index(band) for band in combo]\n",
    "            except ValueError as e:\n",
    "                print(f\"Invalid band in combo {combo}: {e}\")\n",
    "                continue\n",
    "\n",
    "            combo_img = tile[:,:,indices]\n",
    "\n",
    "            combo_img = (combo_img - combo_img.min()) / (combo_img.max() - combo_img.min() + 1e-6)\n",
    "            combo_img = (combo_img * 255).astype(np.uint8)\n",
    "\n",
    "            combo_name = \"_\".join(combo)\n",
    "            save_dir = os.path.join(parent_save_path, data_type, combo_name)\n",
    "            os.makedirs(save_dir, exist_ok=True)\n",
    "            save_path = os.path.join(save_dir, f\"{image_id}.{image_format}\")\n",
    "\n",
    "            im = Image.fromarray(combo_img)\n",
    "            im.save(save_path)\n",
    "\n",
    "print(\"Starting composite image generation...\")\n",
    "generate_and_save_composite_images(\n",
    "     df = train_df,\n",
    "     combinations = CFG.IMAGE_COMBINATIONS,\n",
    "     parent_save_path = CFG.PARENT_SAVE_PATH,\n",
    "     image_format = 'png',\n",
    "     data_type='train'\n",
    ")\n",
    "generate_and_save_composite_images(\n",
    "     df = test_df,\n",
    "     combinations = CFG.IMAGE_COMBINATIONS,\n",
    "     parent_save_path = CFG.PARENT_SAVE_PATH,\n",
    "     image_format = 'png',\n",
    "     data_type='test'\n",
    ")\n",
    "print(\"Image generation complete.\")\n",
    "\n",
    "CURRENT_COMBINATION_NAME = 'nir_green_blue'\n",
    "\n",
    "train_df['image_path'] = train_df['ID'].apply(lambda x: os.path.join(CFG.PARENT_SAVE_PATH, 'train', CURRENT_COMBINATION_NAME, f'{x}.png'))\n",
    "test_df['image_path'] = test_df['ID'].apply(lambda x: os.path.join(CFG.PARENT_SAVE_PATH, 'test', CURRENT_COMBINATION_NAME, f'{x}.png'))\n",
    "\n",
    "\n",
    "skf = StratifiedKFold(n_splits=CFG.n_splits, shuffle=True, random_state=CFG.seed)\n",
    "train_df['fold'] = -1\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(train_df, train_df['label'])):\n",
    "    train_df.loc[val_idx, 'fold'] = fold\n",
    "print(\"\\nFold distribution:\\n\", train_df['fold'].value_counts())\n",
    "\n",
    "class AlbumentationsTransform(RandTransform):\n",
    "    split_idx, order = None, 2\n",
    "    def __init__(self, train_aug, valid_aug): store_attr()\n",
    "\n",
    "    def before_call(self, b, split_idx):\n",
    "        self.idx = split_idx\n",
    "\n",
    "    def encodes(self, img: PILImage):\n",
    "        if self.idx == 0:\n",
    "            aug_img = self.train_aug(image=np.array(img))['image']\n",
    "        else:\n",
    "            aug_img = self.valid_aug(image=np.array(img))['image']\n",
    "        return PILImage.create(aug_img)\n",
    "# Make some augs for train\n",
    "def get_train_aug():\n",
    "    return alb.Compose([\n",
    "        alb.Resize(CFG.image_size, CFG.image_size),\n",
    "        alb.HorizontalFlip(p=0.5),\n",
    "        alb.VerticalFlip(p=0.5),\n",
    "    ], p=1.)\n",
    "\n",
    "def get_valid_aug():\n",
    "    return alb.Compose([\n",
    "        alb.Resize(CFG.image_size, CFG.image_size),\n",
    "    ], p=1.0)\n",
    "\n",
    "item_tfms = AlbumentationsTransform(get_train_aug(), get_valid_aug())\n",
    "batch_tfms = [Normalize.from_stats(*imagenet_stats)]\n",
    "\n",
    "def get_datablock(df, fold=0, bs = CFG.batch_size):\n",
    "    return DataBlock(\n",
    "        blocks = (ImageBlock, CategoryBlock),\n",
    "        get_x = ColReader('image_path'),\n",
    "        get_y = ColReader('label'),\n",
    "        splitter = IndexSplitter(df[df['fold'] == fold].index),\n",
    "        item_tfms = item_tfms,\n",
    "        batch_tfms = batch_tfms\n",
    "    ).dataloaders(df, bs=bs, seed= CFG.seed)\n",
    "\n",
    "metrics = [accuracy, F1Score(average='binary')]\n",
    "\n",
    "oof_preds = np.zeros((len(train_df), CFG.num_classes))\n",
    "all_test_preds = []\n",
    "\n",
    "for fold in range(CFG.n_splits):\n",
    "    if COMET_API_KEY != \"YOUR_COMET_API_KEY\" and COMET_API_KEY != \"\":\n",
    "        exp = comet_ml.Experiment(\n",
    "            api_key=COMET_API_KEY,\n",
    "            project_name=COMET_PROJECT_NAME,\n",
    "            auto_output_logging=\"simple\"\n",
    "        )\n",
    "        exp.set_name(f\"fastai_beitv2_fold_{fold+1}_{CURRENT_COMBINATION_NAME}\")\n",
    "\n",
    "        exp.log_parameters({\n",
    "            \"n_splits\": CFG.n_splits,\n",
    "            \"seed\": CFG.seed,\n",
    "            \"image_size\": CFG.image_size,\n",
    "            \"model_name\": CFG.model_name,\n",
    "            \"batch_size\": CFG.batch_size,\n",
    "            \"epochs\": CFG.epochs,\n",
    "            \"tta_n\": CFG.tta,\n",
    "            \"fold_id\": fold,\n",
    "            \"image_combination\": CURRENT_COMBINATION_NAME\n",
    "        })\n",
    "    else:\n",
    "        print(\"Comet ML API key not set or is default. Skipping Comet ML logging for this run.\")\n",
    "        exp = None\n",
    "\n",
    "    print(f\"\\n{'='*100}\")\n",
    "    print(f\"Training on fold : {fold} and validating on fold : {fold}\")\n",
    "    print(f\"{'='*100}\")\n",
    "\n",
    "    dls = get_datablock(train_df, fold, CFG.batch_size)\n",
    "\n",
    "    learn = vision_learner(\n",
    "        dls,\n",
    "        CFG.model_name,\n",
    "        loss_func = CrossEntropyLossFlat(),\n",
    "        metrics = metrics,\n",
    "        cbs = [SaveModelCallback(monitor = 'f1_score', comp = np.greater, fname=f'best_model_fold_{fold}_{CURRENT_COMBINATION_NAME}')]\n",
    "    )\n",
    "\n",
    "    print(\"Finding optimal learning rate...\")\n",
    "    lr_min, lr_steep = learn.lr_find(suggest_funcs=(valley, slide))\n",
    "    print(f\"Suggested LR from valley: {lr_min}, from slide: {lr_steep}\")\n",
    "    learn.fine_tune(CFG.epochs, lr_min)\n",
    "#Logging experiment\n",
    "    if exp:\n",
    "        for i, row in enumerate(learn.recorder.values):\n",
    "            epoch_num = i\n",
    "            train_loss = row[0]\n",
    "            val_loss = row[1]\n",
    "            val_accuracy = row[2]\n",
    "            val_f1 = row[3]\n",
    "            current_lr = learn.opt.param_groups[0]['lr']\n",
    "\n",
    "            exp.log_metrics({\n",
    "                \"train_loss\": train_loss,\n",
    "                \"val_loss\": val_loss,\n",
    "                \"val_f1\": val_f1,\n",
    "                \"val_accuracy\": val_accuracy,\n",
    "                \"learning_rate\": current_lr\n",
    "            }, step=epoch_num)\n",
    "\n",
    "    val_idx = dls.valid.items.index\n",
    "    val_dl = learn.dls.valid\n",
    "    oof_val_preds, _ = learn.tta(dl= val_dl, n=CFG.tta)\n",
    "    oof_preds[val_idx] = oof_val_preds.numpy()\n",
    "\n",
    "    test_dl = learn.dls.test_dl(test_df)\n",
    "    preds, _ = learn.tta(dl= test_dl, n=CFG.tta)\n",
    "    all_test_preds.append(preds.numpy())\n",
    "\n",
    "    if exp:\n",
    "        exp.end()\n",
    "\n",
    "    del learn, dls\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "# Making final averaged preds\n",
    "print(\"\\n--- Final evaluation ---\")\n",
    "train_df['oof_preds'] = list(oof_preds)\n",
    "\n",
    "train_df['predicted_label'] = train_df['oof_preds'].apply(\n",
    "    lambda preds: 1 if preds[1] > 0.5 else 0\n",
    ")\n",
    "y_true_oof = train_df['label'].values\n",
    "y_pred_oof = train_df['predicted_label'].values\n",
    "\n",
    "final_oof_f1 = f1_score(y_true_oof, y_pred_oof, average='binary', zero_division=0)\n",
    "print(f\"Final F1_Score on OOF predictions: {final_oof_f1:.4f}\")\n",
    "\n",
    "final_test_preds_avg = np.mean(all_test_preds, axis=0)\n",
    "test_df['label'] = (final_test_preds_avg[:, 1] > 0.5).astype(int)\n",
    "\n",
    "submission_df = test_df[['ID', 'label']]\n",
    "submission_output_path = os.path.join(CFG.PARENT_SAVE_PATH, \"submission.csv\")\n",
    "submission_df.to_csv(submission_output_path, index=False)\n",
    "print(f\"Submission file saved to: {submission_output_path}\")"
   ],
   "metadata": {
    "trusted": true,
    "scrolled": true,
    "execution": {
     "iopub.status.busy": "2025-08-03T14:35:40.181873Z",
     "iopub.execute_input": "2025-08-03T14:35:40.182228Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "text": "/usr/local/lib/python3.11/dist-packages/albumentations/__init__.py:28: UserWarning: A new version of Albumentations is available: '2.0.8' (you have '2.0.4'). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n  check_for_updates()\n",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "Distribution of labels in training set:\n label\n0    5892\n1    1255\nName: count, dtype: int64\nStarting composite image generation...\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": "Generating train images: 100%|██████████| 7146/7146 [01:31<00:00, 78.46it/s]\nGenerating test images: 100%|██████████| 5398/5398 [01:07<00:00, 80.39it/s]\n",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "Image generation complete.\n\nFold distribution:\n fold\n2    2382\n0    2382\n1    2382\nName: count, dtype: int64\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": "\u001B[1;38;5;214mCOMET WARNING:\u001B[0m To get all data logged automatically, import comet_ml before the following modules: torch, sklearn, fastai.\n\u001B[1;38;5;214mCOMET WARNING:\u001B[0m As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n\u001B[1;38;5;39mCOMET INFO:\u001B[0m Experiment is live on comet.com https://www.comet.com/makar-rybkin/classification-for-landslide-detection-ensamble-pytorch/1c143a3184364c249b8a47cfcdb693b9\n\n\u001B[1;38;5;39mCOMET INFO:\u001B[0m Couldn't find a Git repository in '/kaggle/working' nor in any parent directory. Set `COMET_GIT_DIRECTORY` if your Git Repository is elsewhere.\n",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "\n====================================================================================================\nTraining on fold : 0 and validating on fold : 0\n====================================================================================================\n",
     "output_type": "stream"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "model.safetensors:   0%|          | 0.00/1.22G [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "471149bc4c75417181ab791478fe0949"
      }
     },
     "metadata": {}
    },
    {
     "name": "stdout",
     "text": "Finding optimal learning rate...\n",
     "output_type": "stream"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": ""
     },
     "metadata": {}
    },
    {
     "name": "stderr",
     "text": "/usr/local/lib/python3.11/dist-packages/fastai/learner.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  state = torch.load(file, map_location=device, **torch_load_kwargs)\n",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "Suggested LR from valley: 0.001737800776027143, from slide: 0.004365158267319202\n",
     "output_type": "stream"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: left;\">\n      <th>epoch</th>\n      <th>train_loss</th>\n      <th>valid_loss</th>\n      <th>accuracy</th>\n      <th>f1_score</th>\n      <th>time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>0.448012</td>\n      <td>0.301572</td>\n      <td>0.869857</td>\n      <td>0.658590</td>\n      <td>09:06</td>\n    </tr>\n  </tbody>\n</table>"
     },
     "metadata": {}
    },
    {
     "name": "stdout",
     "text": "Better model found at epoch 0 with f1_score value: 0.658590308370044.\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": "/usr/local/lib/python3.11/dist-packages/fastai/learner.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  state = torch.load(file, map_location=device, **torch_load_kwargs)\n",
     "output_type": "stream"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: left;\">\n      <th>epoch</th>\n      <th>train_loss</th>\n      <th>valid_loss</th>\n      <th>accuracy</th>\n      <th>f1_score</th>\n      <th>time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>0.293751</td>\n      <td>0.204891</td>\n      <td>0.921914</td>\n      <td>0.758442</td>\n      <td>12:08</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>0.237271</td>\n      <td>0.254750</td>\n      <td>0.901763</td>\n      <td>0.741722</td>\n      <td>12:09</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.199209</td>\n      <td>0.203052</td>\n      <td>0.924853</td>\n      <td>0.805223</td>\n      <td>12:08</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.148014</td>\n      <td>0.156478</td>\n      <td>0.938287</td>\n      <td>0.816479</td>\n      <td>12:08</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.118985</td>\n      <td>0.137373</td>\n      <td>0.947523</td>\n      <td>0.851720</td>\n      <td>12:07</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.069379</td>\n      <td>0.151930</td>\n      <td>0.945004</td>\n      <td>0.844970</td>\n      <td>12:06</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>0.050955</td>\n      <td>0.164925</td>\n      <td>0.950882</td>\n      <td>0.849807</td>\n      <td>12:07</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>0.020389</td>\n      <td>0.184989</td>\n      <td>0.950462</td>\n      <td>0.856796</td>\n      <td>12:06</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>0.024365</td>\n      <td>0.179128</td>\n      <td>0.947103</td>\n      <td>0.849642</td>\n      <td>12:07</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>0.010567</td>\n      <td>0.184832</td>\n      <td>0.947523</td>\n      <td>0.852768</td>\n      <td>12:04</td>\n    </tr>\n  </tbody>\n</table>"
     },
     "metadata": {}
    },
    {
     "name": "stdout",
     "text": "Better model found at epoch 0 with f1_score value: 0.7584415584415585.\nBetter model found at epoch 2 with f1_score value: 0.8052230685527747.\nBetter model found at epoch 3 with f1_score value: 0.8164794007490638.\nBetter model found at epoch 4 with f1_score value: 0.8517200474495848.\nBetter model found at epoch 7 with f1_score value: 0.8567961165048543.\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": "/usr/local/lib/python3.11/dist-packages/fastai/learner.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  state = torch.load(file, map_location=device, **torch_load_kwargs)\n",
     "output_type": "stream"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      <progress value='0' class='' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      \n    </div>\n    \n"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": ""
     },
     "metadata": {}
    },
    {
     "name": "stderr",
     "text": "/usr/local/lib/python3.11/dist-packages/fastai/learner.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  state = torch.load(file, map_location=device, **torch_load_kwargs)\n",
     "output_type": "stream"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      <progress value='0' class='' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      \n    </div>\n    \n"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": ""
     },
     "metadata": {}
    },
    {
     "name": "stderr",
     "text": "\u001B[1;38;5;39mCOMET INFO:\u001B[0m ---------------------------------------------------------------------------------------\n\u001B[1;38;5;39mCOMET INFO:\u001B[0m Comet.ml Experiment Summary\n\u001B[1;38;5;39mCOMET INFO:\u001B[0m ---------------------------------------------------------------------------------------\n\u001B[1;38;5;39mCOMET INFO:\u001B[0m   Data:\n\u001B[1;38;5;39mCOMET INFO:\u001B[0m     display_summary_level : 1\n\u001B[1;38;5;39mCOMET INFO:\u001B[0m     name                  : fastai_beitv2_fold_1_nir_green_blue\n\u001B[1;38;5;39mCOMET INFO:\u001B[0m     url                   : https://www.comet.com/makar-rybkin/classification-for-landslide-detection-ensamble-pytorch/1c143a3184364c249b8a47cfcdb693b9\n\u001B[1;38;5;39mCOMET INFO:\u001B[0m   Metrics [count] (min, max):\n\u001B[1;38;5;39mCOMET INFO:\u001B[0m     learning_rate     : 9.18503919535745e-11\n\u001B[1;38;5;39mCOMET INFO:\u001B[0m     train_loss [10]   : (0.010567007586359978, 0.2937512993812561)\n\u001B[1;38;5;39mCOMET INFO:\u001B[0m     val_accuracy [10] : (0.9017632007598877, 0.9508816003799438)\n\u001B[1;38;5;39mCOMET INFO:\u001B[0m     val_f1 [10]       : (0.7417218543046357, 0.8567961165048543)\n\u001B[1;38;5;39mCOMET INFO:\u001B[0m     val_loss [10]     : (0.13737273216247559, 0.2547500729560852)\n\u001B[1;38;5;39mCOMET INFO:\u001B[0m   Others:\n\u001B[1;38;5;39mCOMET INFO:\u001B[0m     Name : fastai_beitv2_fold_1_nir_green_blue\n\u001B[1;38;5;39mCOMET INFO:\u001B[0m   Parameters:\n\u001B[1;38;5;39mCOMET INFO:\u001B[0m     batch_size        : 16\n\u001B[1;38;5;39mCOMET INFO:\u001B[0m     epochs            : 10\n\u001B[1;38;5;39mCOMET INFO:\u001B[0m     fold_id           : 0\n\u001B[1;38;5;39mCOMET INFO:\u001B[0m     image_combination : nir_green_blue\n\u001B[1;38;5;39mCOMET INFO:\u001B[0m     image_size        : 196\n\u001B[1;38;5;39mCOMET INFO:\u001B[0m     model_name        : eva_large_patch14_196.in22k_ft_in22k_in1k\n\u001B[1;38;5;39mCOMET INFO:\u001B[0m     n_splits          : 3\n\u001B[1;38;5;39mCOMET INFO:\u001B[0m     seed              : 42\n\u001B[1;38;5;39mCOMET INFO:\u001B[0m     tta_n             : 4\n\u001B[1;38;5;39mCOMET INFO:\u001B[0m   Uploads:\n\u001B[1;38;5;39mCOMET INFO:\u001B[0m     environment details : 1\n\u001B[1;38;5;39mCOMET INFO:\u001B[0m     filename            : 1\n\u001B[1;38;5;39mCOMET INFO:\u001B[0m     installed packages  : 1\n\u001B[1;38;5;39mCOMET INFO:\u001B[0m     notebook            : 1\n\u001B[1;38;5;39mCOMET INFO:\u001B[0m     os packages         : 1\n\u001B[1;38;5;39mCOMET INFO:\u001B[0m     source_code         : 1\n\u001B[1;38;5;39mCOMET INFO:\u001B[0m \n\u001B[1;38;5;214mCOMET WARNING:\u001B[0m To get all data logged automatically, import comet_ml before the following modules: torch, sklearn, fastai.\n\u001B[1;38;5;214mCOMET WARNING:\u001B[0m To get all data logged automatically, import comet_ml before the following modules: torch, sklearn, fastai.\n\u001B[1;38;5;214mCOMET WARNING:\u001B[0m As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n\u001B[1;38;5;39mCOMET INFO:\u001B[0m Experiment is live on comet.com https://www.comet.com/makar-rybkin/classification-for-landslide-detection-ensamble-pytorch/264998cb6f984d74b55de25e4592e076\n\n\u001B[1;38;5;39mCOMET INFO:\u001B[0m Couldn't find a Git repository in '/kaggle/working' nor in any parent directory. Set `COMET_GIT_DIRECTORY` if your Git Repository is elsewhere.\n",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "\n====================================================================================================\nTraining on fold : 1 and validating on fold : 1\n====================================================================================================\nFinding optimal learning rate...\n",
     "output_type": "stream"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": ""
     },
     "metadata": {}
    },
    {
     "name": "stderr",
     "text": "/usr/local/lib/python3.11/dist-packages/fastai/learner.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  state = torch.load(file, map_location=device, **torch_load_kwargs)\n",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "Suggested LR from valley: 0.0063095735386013985, from slide: 0.0030199517495930195\n",
     "output_type": "stream"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: left;\">\n      <th>epoch</th>\n      <th>train_loss</th>\n      <th>valid_loss</th>\n      <th>accuracy</th>\n      <th>f1_score</th>\n      <th>time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>0.441549</td>\n      <td>0.347813</td>\n      <td>0.874055</td>\n      <td>0.635036</td>\n      <td>09:05</td>\n    </tr>\n  </tbody>\n</table>"
     },
     "metadata": {}
    },
    {
     "name": "stdout",
     "text": "Better model found at epoch 0 with f1_score value: 0.635036496350365.\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": "/usr/local/lib/python3.11/dist-packages/fastai/learner.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  state = torch.load(file, map_location=device, **torch_load_kwargs)\n",
     "output_type": "stream"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: left;\">\n      <th>epoch</th>\n      <th>train_loss</th>\n      <th>valid_loss</th>\n      <th>accuracy</th>\n      <th>f1_score</th>\n      <th>time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>0.227831</td>\n      <td>0.212303</td>\n      <td>0.911419</td>\n      <td>0.772384</td>\n      <td>12:07</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>0.272677</td>\n      <td>0.180713</td>\n      <td>0.922334</td>\n      <td>0.752343</td>\n      <td>12:08</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.203154</td>\n      <td>0.209302</td>\n      <td>0.918556</td>\n      <td>0.744737</td>\n      <td>12:07</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.210329</td>\n      <td>0.460284</td>\n      <td>0.844668</td>\n      <td>0.206009</td>\n      <td>12:06</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.151488</td>\n      <td>0.309905</td>\n      <td>0.903443</td>\n      <td>0.620462</td>\n      <td>12:06</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.100750</td>\n      <td>0.162909</td>\n      <td>0.940386</td>\n      <td>0.835648</td>\n      <td>12:06</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>0.046920</td>\n      <td>0.193001</td>\n      <td>0.942905</td>\n      <td>0.846154</td>\n      <td>12:07</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>0.022945</td>\n      <td>0.161561</td>\n      <td>0.954240</td>\n      <td>0.867558</td>\n      <td>12:07</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>0.011948</td>\n      <td>0.174779</td>\n      <td>0.957179</td>\n      <td>0.875610</td>\n      <td>12:06</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>0.006109</td>\n      <td>0.182476</td>\n      <td>0.958018</td>\n      <td>0.876847</td>\n      <td>12:06</td>\n    </tr>\n  </tbody>\n</table>"
     },
     "metadata": {}
    },
    {
     "name": "stdout",
     "text": "Better model found at epoch 0 with f1_score value: 0.7723840345199569.\nBetter model found at epoch 5 with f1_score value: 0.8356481481481483.\nBetter model found at epoch 6 with f1_score value: 0.8461538461538461.\nBetter model found at epoch 7 with f1_score value: 0.867557715674362.\nBetter model found at epoch 8 with f1_score value: 0.875609756097561.\nBetter model found at epoch 9 with f1_score value: 0.8768472906403941.\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": "/usr/local/lib/python3.11/dist-packages/fastai/learner.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  state = torch.load(file, map_location=device, **torch_load_kwargs)\n",
     "output_type": "stream"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      <progress value='0' class='' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      \n    </div>\n    \n"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": ""
     },
     "metadata": {}
    },
    {
     "name": "stderr",
     "text": "/usr/local/lib/python3.11/dist-packages/fastai/learner.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  state = torch.load(file, map_location=device, **torch_load_kwargs)\n",
     "output_type": "stream"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      <progress value='0' class='' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      \n    </div>\n    \n"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": ""
     },
     "metadata": {}
    },
    {
     "name": "stderr",
     "text": "\u001B[1;38;5;39mCOMET INFO:\u001B[0m ---------------------------------------------------------------------------------------\n\u001B[1;38;5;39mCOMET INFO:\u001B[0m Comet.ml Experiment Summary\n\u001B[1;38;5;39mCOMET INFO:\u001B[0m ---------------------------------------------------------------------------------------\n\u001B[1;38;5;39mCOMET INFO:\u001B[0m   Data:\n\u001B[1;38;5;39mCOMET INFO:\u001B[0m     display_summary_level : 1\n\u001B[1;38;5;39mCOMET INFO:\u001B[0m     name                  : fastai_beitv2_fold_2_nir_green_blue\n\u001B[1;38;5;39mCOMET INFO:\u001B[0m     url                   : https://www.comet.com/makar-rybkin/classification-for-landslide-detection-ensamble-pytorch/264998cb6f984d74b55de25e4592e076\n\u001B[1;38;5;39mCOMET INFO:\u001B[0m   Metrics [count] (min, max):\n\u001B[1;38;5;39mCOMET INFO:\u001B[0m     learning_rate     : 3.3348863147847135e-10\n\u001B[1;38;5;39mCOMET INFO:\u001B[0m     train_loss [10]   : (0.006108585279434919, 0.27267661690711975)\n\u001B[1;38;5;39mCOMET INFO:\u001B[0m     val_accuracy [10] : (0.8446683287620544, 0.9580184817314148)\n\u001B[1;38;5;39mCOMET INFO:\u001B[0m     val_f1 [10]       : (0.20600858369098715, 0.8768472906403941)\n\u001B[1;38;5;39mCOMET INFO:\u001B[0m     val_loss [10]     : (0.16156060993671417, 0.46028390526771545)\n\u001B[1;38;5;39mCOMET INFO:\u001B[0m   Others:\n\u001B[1;38;5;39mCOMET INFO:\u001B[0m     Name : fastai_beitv2_fold_2_nir_green_blue\n\u001B[1;38;5;39mCOMET INFO:\u001B[0m   Parameters:\n\u001B[1;38;5;39mCOMET INFO:\u001B[0m     batch_size        : 16\n\u001B[1;38;5;39mCOMET INFO:\u001B[0m     epochs            : 10\n\u001B[1;38;5;39mCOMET INFO:\u001B[0m     fold_id           : 1\n\u001B[1;38;5;39mCOMET INFO:\u001B[0m     image_combination : nir_green_blue\n\u001B[1;38;5;39mCOMET INFO:\u001B[0m     image_size        : 196\n\u001B[1;38;5;39mCOMET INFO:\u001B[0m     model_name        : eva_large_patch14_196.in22k_ft_in22k_in1k\n\u001B[1;38;5;39mCOMET INFO:\u001B[0m     n_splits          : 3\n\u001B[1;38;5;39mCOMET INFO:\u001B[0m     seed              : 42\n\u001B[1;38;5;39mCOMET INFO:\u001B[0m     tta_n             : 4\n\u001B[1;38;5;39mCOMET INFO:\u001B[0m   Uploads:\n\u001B[1;38;5;39mCOMET INFO:\u001B[0m     environment details : 1\n\u001B[1;38;5;39mCOMET INFO:\u001B[0m     filename            : 1\n\u001B[1;38;5;39mCOMET INFO:\u001B[0m     installed packages  : 1\n\u001B[1;38;5;39mCOMET INFO:\u001B[0m     notebook            : 1\n\u001B[1;38;5;39mCOMET INFO:\u001B[0m     os packages         : 1\n\u001B[1;38;5;39mCOMET INFO:\u001B[0m     source_code         : 1\n\u001B[1;38;5;39mCOMET INFO:\u001B[0m \n\u001B[1;38;5;214mCOMET WARNING:\u001B[0m To get all data logged automatically, import comet_ml before the following modules: torch, sklearn, fastai.\n\u001B[1;38;5;214mCOMET WARNING:\u001B[0m To get all data logged automatically, import comet_ml before the following modules: torch, sklearn, fastai.\n\u001B[1;38;5;214mCOMET WARNING:\u001B[0m As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n\u001B[1;38;5;39mCOMET INFO:\u001B[0m Couldn't find a Git repository in '/kaggle/working' nor in any parent directory. Set `COMET_GIT_DIRECTORY` if your Git Repository is elsewhere.\n\u001B[1;38;5;39mCOMET INFO:\u001B[0m Experiment is live on comet.com https://www.comet.com/makar-rybkin/classification-for-landslide-detection-ensamble-pytorch/851315d49dea460aa449ad72b5e25461\n\n",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "\n====================================================================================================\nTraining on fold : 2 and validating on fold : 2\n====================================================================================================\nFinding optimal learning rate...\n",
     "output_type": "stream"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": ""
     },
     "metadata": {}
    },
    {
     "name": "stderr",
     "text": "/usr/local/lib/python3.11/dist-packages/fastai/learner.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  state = torch.load(file, map_location=device, **torch_load_kwargs)\n",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "Suggested LR from valley: 0.005248074419796467, from slide: 0.0014454397605732083\n",
     "output_type": "stream"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: left;\">\n      <th>epoch</th>\n      <th>train_loss</th>\n      <th>valid_loss</th>\n      <th>accuracy</th>\n      <th>f1_score</th>\n      <th>time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>0.472572</td>\n      <td>0.302139</td>\n      <td>0.877414</td>\n      <td>0.679121</td>\n      <td>09:04</td>\n    </tr>\n  </tbody>\n</table>"
     },
     "metadata": {}
    },
    {
     "name": "stdout",
     "text": "Better model found at epoch 0 with f1_score value: 0.6791208791208792.\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": "/usr/local/lib/python3.11/dist-packages/fastai/learner.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  state = torch.load(file, map_location=device, **torch_load_kwargs)\n",
     "output_type": "stream"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      <progress value='5' class='' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      50.00% [5/10 1:00:48&lt;1:00:48]\n    </div>\n    \n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: left;\">\n      <th>epoch</th>\n      <th>train_loss</th>\n      <th>valid_loss</th>\n      <th>accuracy</th>\n      <th>f1_score</th>\n      <th>time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>0.237085</td>\n      <td>0.198115</td>\n      <td>0.918976</td>\n      <td>0.735254</td>\n      <td>12:08</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>0.246559</td>\n      <td>0.166985</td>\n      <td>0.927372</td>\n      <td>0.810515</td>\n      <td>12:07</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.213645</td>\n      <td>0.170081</td>\n      <td>0.923174</td>\n      <td>0.803014</td>\n      <td>12:08</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.174028</td>\n      <td>0.114600</td>\n      <td>0.951721</td>\n      <td>0.855709</td>\n      <td>12:07</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.117723</td>\n      <td>0.339816</td>\n      <td>0.890008</td>\n      <td>0.543554</td>\n      <td>12:08</td>\n    </tr>\n  </tbody>\n</table><p>\n\n    <div>\n      <progress value='280' class='' max='297' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      94.28% [280/297 09:52&lt;00:35 0.1029]\n    </div>\n    "
     },
     "metadata": {}
    },
    {
     "name": "stdout",
     "text": "Better model found at epoch 0 with f1_score value: 0.7352537722908093.\nBetter model found at epoch 1 with f1_score value: 0.8105147864184009.\nBetter model found at epoch 3 with f1_score value: 0.8557089084065245.\n",
     "output_type": "stream"
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "train_df['oof_preds'] = list(oof_preds)\n\ntrain_df['predicted_label'] = train_df['oof_preds'].apply(\n    lambda preds: 1 if preds[1] > 0.5 else 0\n)\ny_true_oof = train_df['label'].values\ny_pred_oof = train_df['predicted_label'].values\n\nfinal_oof_f1 = f1_score(y_true_oof, y_pred_oof, average='binary', zero_division=0)\nprint(f\"Final F1_Score on OOF predictions: {final_oof_f1:.4f}\")\n\nfinal_test_preds_avg = np.mean(all_test_preds, axis=0)\ntest_df['label'] = (final_test_preds_avg[:, 1] > 0.465).astype(int)\n\nsubmission_df = test_df[['ID', 'label']]\nsubmission_output_path = os.path.join(CFG.PARENT_SAVE_PATH, \"submission.csv\")\nsubmission_df.to_csv(submission_output_path, index=False)\nprint(f\"Submission file saved to: {submission_output_path}\")",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  }
 ]
}
