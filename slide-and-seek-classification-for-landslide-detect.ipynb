{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.11",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "sourceId": 91496,
     "databundleVersionId": 11802066,
     "sourceType": "competition"
    },
    {
     "sourceId": 11474913,
     "sourceType": "datasetVersion",
     "datasetId": 7191644
    }
   ],
   "dockerImageVersionId": 31012,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": true
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Решение соревнования https://zindi.africa/competitions/classification-for-landslide-detection демонстрирует процесс создания и обучения модели глубокого обучения для бинарной классификации оползней на основе мультиспектральных данных и Sentinel-2.\n",
    "### Метрика соревнования - f1\n",
    "### После импорта из kaggle notebook некоторые выводы после запуска кода пропали"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Выполняем установку библиотеки comet_ml. Comet ML – это платформа для отслеживания, сравнения и оптимизации экспериментов машинного обучения"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Import necessary libraries\n",
    "!pip install comet_ml > /dev/null 2>&1"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Импорт необходимых библиотек"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import comet_ml\n",
    "COMET_API_KEY = \"My CometML\"\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout, BatchNormalization, Input, GlobalAveragePooling2D\n",
    "from tensorflow.keras import backend as K\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from scipy.ndimage import rotate, shift, zoom\n",
    "data = \"/kaggle/input/slideandseekclasificationlandslidedetectiondataset\""
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Определение путей к данным и предварительная загрузка CSV-файлов train и test"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "train_csv_path = f'{data}/Train.csv'\n",
    "test_csv_path = f'{data}/Test.csv'\n",
    "train_data_path = f'{data}/train_data/train_data'\n",
    "test_data_path = f'{data}/test_data/test_data'\n",
    "\n",
    "train_df = pd.read_csv(train_csv_path)\n",
    "print(\"Train.csv:\")\n",
    "print(train_df.head())"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Визуализация распределения классов (Нет последствий оползня/ после оползня)"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "label_counts = train_df['label'].value_counts()\n",
    "labels = ['No Landslide', 'Landslide']\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.bar(labels, label_counts.values, color=['skyblue', 'salmon'])\n",
    "plt.xlabel(\"Class Label\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Distribution of Labels in Training Set\")\n",
    "plt.show()"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Как видно из графика есть сильный дисбаланс классов No Landslide ~ 6000 изображений, Landslide ~ 1400 изображений\n",
    "### Далее эта проблема будет решена с помощью Focal loss"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Функция загрузки и нормализации изображений, а также их визуализация\n",
    "###  Изображения состоят из 12 каналов (4 оптических из Sentinel-2 и 8 SAR из Sentinel-1) и размером 64x64. Для каждого канала выполняется надежная нормализация по процентилям (2-й и 98-й), чтобы сделать значения пикселей в диапазоне [0, 1] и уменьшить влияние выбросов, которые могут быть в спутниковых данных. Также были протестированы нормализация по 1/99 процентилям и minmax шкалирование(закоментированный код), но они дали результаты похуже."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def load_and_normalize_npy_image(image_id, folder_path):\n",
    "    image_path = os.path.join(folder_path, f\"{image_id}.npy\")\n",
    "    \n",
    "    if not os.path.exists(image_path):\n",
    "        raise FileNotFoundError(f\"Image not found: {image_path}\")\n",
    "    \n",
    "    img = np.load(image_path).astype(np.float32)\n",
    "\n",
    "    normalized_img = img\n",
    "    for band in range(img.shape[2]):\n",
    "        band_data = img[:, :, band]\n",
    "        \n",
    "        p2, p98 = np.percentile(band_data, (2, 98))\n",
    "        normalized_img[:, :, band] = np.clip((band_data - p2) / (p98 - p2 + 1e-6), 0, 1)\n",
    "        \n",
    "    #     p1, p99 = np.percentile(band_data, (1, 99))\n",
    "\n",
    "    #     clipped_data = np.clip(band_data, p1, p99)\n",
    "    #     mean_val = np.mean(clipped_data)\n",
    "    #     std_val = np.std(clipped_data)\n",
    "        \n",
    "    #     if std_val > 0:\n",
    "    #         normalized_img[:, :, band] = (clipped_data - mean_val) / std_val\n",
    "    #     else:\n",
    "    #         normalized_img[:, :, band] = clipped_data - mean_val\n",
    "    \n",
    "    # for band in range(img.shape[2]):\n",
    "    #     band_data = normalized_img[:, :, band]\n",
    "    #     min_val, max_val = np.min(band_data), np.max(band_data)\n",
    "    #     if max_val > min_val:\n",
    "    #         normalized_img[:, :, band] = (band_data - min_val) / (max_val - min_val)\n",
    "    \n",
    "    return normalized_img\n",
    "\n",
    "band_descriptions = [\n",
    "    \"Red\", \"Green\", \"Blue\", \"Near Infrared\",\n",
    "    \"Descending VV (Vertical-Vertical)\", \"Descending VH (Vertical-Horizontal)\",\n",
    "    \"Descending Diff VV\", \"Descending Diff VH\",\n",
    "    \"Ascending VV (Vertical-Vertical)\", \"Ascending VH (Vertical-Horizontal)\",\n",
    "    \"Ascending Diff VV\", \"Ascending Diff VH\"\n",
    "]\n",
    "\n",
    "example_ids = train_df['ID'].sample(2,random_state = 42).values\n",
    "\n",
    "for image_id in example_ids:\n",
    "    img_normalized = load_and_normalize_npy_image(image_id, train_data_path)\n",
    "\n",
    "    fig, axes = plt.subplots(3, 4, figsize=(20, 12))\n",
    "    fig.suptitle(f\"Sample Image ID: {image_id} - All 12 Bands\", fontsize=16)\n",
    "\n",
    "    for band in range(12):\n",
    "        row = band // 4\n",
    "        col = band % 4\n",
    "        axes[row, col].imshow(img_normalized[:, :, band], cmap='gray')\n",
    "        axes[row, col].set_title(f\"Band {band + 1}: {band_descriptions[band]}\")\n",
    "        axes[row, col].axis('off')\n",
    "\n",
    "    plt.subplots_adjust(wspace=0.3, hspace=0.4)\n",
    "    plt.show()"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Вот так выглядят два 12 канальных изображения (первые три канала привычные RGB, дальше инфракрсаное и другие виды производимых и принимаемых Sentinel 2 излучений."
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Определение генератора данных для загрузки данных батчами с рандомными примерами из train и применение слуяайных аугментаций ( поворот 15 градусов, сдвиги по ширине и высоте, масштабирование, отражения и заполнение появившихся пропусков у краев.)"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "\n",
    "class LandslideDataGenerator(Sequence):\n",
    "    def __init__(self, df, data_path, batch_size=32, augment=False, shuffle=True):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.data_path = data_path\n",
    "        self.batch_size = batch_size\n",
    "        self.augment = augment\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "        if self.augment:\n",
    "            self.augmentor = ImageDataGenerator(\n",
    "                rotation_range=15,\n",
    "                width_shift_range=0.1,\n",
    "                height_shift_range=0.1,\n",
    "                shear_range=0.1,\n",
    "                zoom_range=0.1,\n",
    "                horizontal_flip=True,\n",
    "                vertical_flip=True,\n",
    "                fill_mode='reflect' \n",
    "            )\n",
    "        else:\n",
    "            self.augmentor = None\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.df) / self.batch_size))\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        self.indexes = np.arange(len(self.df))\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indexes)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        batch_indexes = self.indexes[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        batch_df = self.df.iloc[batch_indexes]\n",
    "        \n",
    "        batch_X = []\n",
    "        batch_y = []\n",
    "        \n",
    "        for _, row in batch_df.iterrows():\n",
    "            image_id = row['ID']\n",
    "            label = row['label']\n",
    "           \n",
    "            image = load_and_normalize_npy_image(image_id, self.data_path)\n",
    "            batch_X.append(image)\n",
    "            batch_y.append(label)\n",
    "        \n",
    "        batch_X = np.array(batch_X, dtype=np.float32)\n",
    "        batch_y = np.array(batch_y, dtype=np.float32).reshape(-1, 1)\n",
    "\n",
    "        if self.augment and self.augmentor:\n",
    "            batch_X = next(self.augmentor.flow(batch_X, batch_size=len(batch_X), shuffle=False))\n",
    "        return batch_X, batch_y\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Проверка работы LandslideDataGenerator"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "folder_path = '/kaggle/input/slideandseekclasificationlandslidedetectiondataset/train_data/train_data/'\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "train_df_split, val_df_split = train_test_split(train_df, test_size=0.2, random_state=42, stratify=train_df['label'])\n",
    "\n",
    "train_gen = LandslideDataGenerator(train_df_split, folder_path, batch_size=batch_size, augment=True, shuffle=True)\n",
    "val_gen = LandslideDataGenerator(val_df_split, folder_path, batch_size=batch_size, augment=False, shuffle=False)\n",
    "\n",
    "X_batch, y_batch = train_gen[0]\n",
    "\n",
    "X_batch.shape, y_batch.shape"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Как видим в X батче 16 изображений 64x64 по 12 каналов и в label(y) батче 16 соответствующих изображениям классов"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Вывод y_batch"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "y_batch"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Определение функции потерь Focal Loss\n",
    "### Focal Loss был разработан для решения проблемы дисбаланса классов в задачах, где один класс значительно преобладает над другим (как в случае с оползнями). Он модифицирует стандартную кросс-энтропийную потерю, уменьшая вес \"легких\" (хорошо классифицируемых) примеров и увеличивая вес \"сложных\" (плохо классифицируемых) примеров, особенно для миноритарного класса.\n",
    "\n",
    "### gamma (параметр фокусировки): контролирует, насколько сильно подавляются \"легкие\" примеры. Большее gamma -> сильнее фокусировка на сложных.\n",
    "\n",
    "### alpha (балансирующий фактор):Для редкого положительного класса alpha обычно устанавливается высоким (например, 0.75 или 0.9 в зависимости от степени дисбаланса). В текущей реализации alpha=None по умолчанию, что означает автоматический расчет весов(по количеству примеров классов в train)."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def focal_loss(gamma=2.0, alpha=0.75):\n",
    "    \"\"\"\n",
    "    Focal Loss for binary classification.\n",
    "\n",
    "    Parameters:\n",
    "        gamma (float): Focusing parameter; typically set to 2.0.\n",
    "        alpha (float): Balancing factor; typically set to 0.25.\n",
    "\n",
    "    Returns:\n",
    "        Binary Focal Loss function.\n",
    "    \"\"\"\n",
    "    def focal_loss_fixed(y_true, y_pred):\n",
    "        y_pred = K.clip(y_pred, K.epsilon(), 1 - K.epsilon())\n",
    "\n",
    "        if alpha is None:\n",
    "\n",
    "            pos_weight = K.mean(1 - y_true)\n",
    "            neg_weight = K.mean(y_true)\n",
    "            alpha_t = tf.where(K.equal(y_true, 1), pos_weight, neg_weight)\n",
    "        else:\n",
    "            alpha_t = tf.where(K.equal(y_true, 1), alpha, 1 - alpha)\n",
    "\n",
    "        p_t = tf.where(K.equal(y_true, 1), y_pred, 1 - y_pred)\n",
    "\n",
    "        fl = -alpha_t * K.pow(1 - p_t, gamma) * K.log(p_t)\n",
    "        return K.mean(fl)\n",
    "    \n",
    "    return focal_loss_fixed"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Стандартные метрики Precision , Recall  и F1-score"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def precision_m(y_true, y_pred):\n",
    "    y_pred_bin = tf.cast(y_pred >= 0.5, tf.float32)\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    true_positives = tf.reduce_sum(y_true * y_pred_bin)\n",
    "    predicted_positives = tf.reduce_sum(y_pred_bin)\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "    y_pred_bin = tf.cast(y_pred >= 0.5, tf.float32)\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    true_positives = tf.reduce_sum(y_true * y_pred_bin)\n",
    "    possible_positives = tf.reduce_sum(y_true)\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2 * ((precision * recall) / (precision + recall + K.epsilon()))"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Далее были проведены более 50 эксперементов над различными архитектурами: простые CNN модели разной глубины, с разными функциями активаций (RelU LeakyReLU, ELU) с разными параметрами для dropout и размероми свертки, с разными гиперпараметрами lr, batch_size и т.д.\n",
    "### График f1 на валидационной выборке всех экспериментов с Cnn:\n",
    "![all_cnn](https://github.com/MakarRybkin/Slide_and_seek_classification/raw/master/images_for_report/all_cnn_f1.png)\n",
    "### При таком подходе удалось достичь f1 =0.8054\n",
    "### График f1 на валидационной выборке лучшего из экспериментов с Cnn:\n",
    "![best_cnn.png](https://github.com/MakarRybkin/Slide_and_seek_classification/raw/master/images_for_report/best_cnn.png)\n",
    "### Пример одной из моделей CNN можно увидеть в закомментированном коде ниже"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# model = Sequential([\n",
    "#\n",
    "#     Input(shape=X_batch.shape[1:]),\n",
    "#     Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "#     BatchNormalization(),\n",
    "#     Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "#     MaxPooling2D((2, 2)),\n",
    "#     Dropout(0.1),\n",
    "    \n",
    "#\n",
    "#     Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "#     BatchNormalization(),\n",
    "#     Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "#     MaxPooling2D((2, 2)),\n",
    "#     Dropout(0.1),\n",
    "    \n",
    "#\n",
    "#     Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "#     BatchNormalization(),\n",
    "#     Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "#     MaxPooling2D((2, 2)),\n",
    "#     Dropout(0.15),\n",
    "    \n",
    "#\n",
    "#     Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
    "#     BatchNormalization(),\n",
    "#     Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
    "#     GlobalAveragePooling2D(),  # Better than Flatten for reducing parameters\n",
    "#     Dropout(0.15),\n",
    "    \n",
    "#\n",
    "#     Dense(64, activation='relu'),\n",
    "#     BatchNormalization(),\n",
    "#     Dropout(0.3),\n",
    "#     Dense(1, activation='sigmoid')\n",
    "# ])\n",
    "\n",
    "# optimizer = AdamW(\n",
    "#     learning_rate=0.005,  \n",
    "#     weight_decay=0.01,\n",
    "#     beta_1=0.9,\n",
    "#     beta_2=0.999\n",
    "# )\n",
    "\n",
    "# model.compile(\n",
    "#         optimizer=optimizer,\n",
    "#         loss=focal_loss(gamma=2.0, alpha=None),  # Auto-balanced\n",
    "#         metrics=[f1_m, precision_m, recall_m]\n",
    "#     )\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### После этого были проведены эксперементы также с разными параметрами и гиперпараметрами для более сложных готовых моделей (EfficientNet(B0 - B7) EfficientNetV2L, разной глубины ResNet и DenseNet после которых шла голова ( head) модели, состоящая из  GlobalAveragePooling2D() для уменьшения  размерности после выхода и несколько слоев FCNN\n",
    "\n",
    "### График f1 на валидационной выборке всех экспериментов с этими архитектурами:\n",
    "\n",
    "![all_ef_res_dense.png](https://github.com/MakarRybkin/Slide_and_seek_classification/raw/master/images_for_report/all_ef_res_dense.png)\n",
    "### В результате лучшие модели оказались EfficientNet B4 (лучший f1 ~ 0.8389), ResNet50 (лучший f1 ~ 0.838) DenseNet_169 (лучший f1 ~ 0.841)\n",
    "\n",
    "### График f1 на валидационной выборке для лучшего эксперимента с EfficientNetB4 :\n",
    "![best_eff_b4.png](https://github.com/MakarRybkin/Slide_and_seek_classification/raw/master/images_for_report/best_eff_b4.png)\n",
    "\n",
    "### График f1 на валидационной выборке для лучшего эксперимента с ResNet50 :\n",
    "![best_resnet.png](https://github.com/MakarRybkin/Slide_and_seek_classification/raw/master/images_for_report/best_resnet.png)\n",
    "\n",
    "### График f1 на валидационной выборке для лучшего эксперимента с DenseNet169:\n",
    "![best_densenet.png](https://github.com/MakarRybkin/Slide_and_seek_classification/raw/master/images_for_report/best_densenet.png)\n",
    "### Закомментированный код для обучения одной из моделей из этой серии можно увидеть ниже"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# from tensorflow.keras.applications import EfficientNetB3 , EfficientNetV2L , DenseNet169, ResNet50\n",
    "# from tensorflow.keras.layers import LeakyReLU, ELU , ReLU\n",
    "# input_shape = X_batch.shape[1:] \n",
    "\n",
    "# base_efficientnet = EfficientNetB3(weights=None, include_top=False, input_shape=input_shape)\n",
    "\n",
    "# # densnet_169 = DenseNet169(weights=None, include_top=False, input_shape=input_shape)\n",
    "\n",
    "# # resnet50 = ResNet50(weights=None, include_top=False, input_shape=input_shape)\n",
    "\n",
    "# model = Sequential([\n",
    "#     base_efficientnet,\n",
    "#     GlobalAveragePooling2D(),\n",
    "    \n",
    "#     Dense(512), \n",
    "#     BatchNormalization(),\n",
    "#     LeakyReLU(alpha = 0.01), \n",
    "#     Dropout(0.3),\n",
    "    \n",
    "#     Dense(256),\n",
    "#     BatchNormalization(),\n",
    "#     LeakyReLU(alpha = 0.01),\n",
    "#     Dropout(0.2),\n",
    "    \n",
    "#     Dense(64),\n",
    "#     BatchNormalization(),\n",
    "#     LeakyReLU(alpha = 0.01),\n",
    "#     Dropout(0.2),\n",
    "#     Dense(1, activation='sigmoid')\n",
    "# ])\n",
    "\n",
    "\n",
    "# optimizer_efficientnet = tf.keras.optimizers.AdamW(\n",
    "#     learning_rate=0.001,\n",
    "#     weight_decay=0.01,\n",
    "#     beta_1=0.9,\n",
    "#     beta_2=0.999\n",
    "# )\n",
    "\n",
    "# model.compile(\n",
    "#     optimizer=optimizer_efficientnet,\n",
    "#     loss=focal_loss(gamma=2.0, alpha=None), \n",
    "#     metrics=[f1_m, precision_m, recall_m] \n",
    "# )\n",
    "\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Определение констант и гиперпараметров\n",
    "\n",
    "### В результате прошлых экспериментов были выявлены лучшие гиперпараметры и архитектуры (из исследуемых) они будут использоваться ниже для объединения в ансамбль"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from tensorflow.keras.applications import EfficientNetB5 , EfficientNetV2L , DenseNet169, ResNet50\n",
    "from tensorflow.keras.layers import LeakyReLU, ELU , ReLU\n",
    "MODEL_TYPES_FOR_ENSEMBLE = [\n",
    "    'EfficientNetB5',\n",
    "    'DenseNet169',\n",
    "    'ResNet50'\n",
    "]\n",
    "NUM_RUNS_PER_MODEL_TYPE = 2\n",
    "BASE_RANDOM_SEED = 100\n",
    "\n",
    "\n",
    "LEARNING_RATE = 0.001\n",
    "BATCH_SIZE_PHASE1 = 16\n",
    "EPOCHS_PHASE1 = 30\n",
    "BATCH_SIZE_PHASE2 = 32\n",
    "EPOCHS_PHASE2_MAX = 70\n",
    "PATIENCE_EARLY_STOPPING = 25\n",
    "PATIENCE_REDUCE_LR = 6\n",
    "MIN_LR = 1e-8\n",
    "DROPOUT_RATE_DENSE1 = 0.2\n",
    "DROPOUT_RATE_DENSE2 = 0.15\n",
    "DROPOUT_RATE_DENSE3 = 0.15\n",
    "\n",
    "COMET_PROJECT_NAME = \"landslide-ensemble-custom-loop\""
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Функция создания и компиляции одной модели (будет использоваться ниже для каждой модели в ансамбле). В зависимости от model_type (EfficientNetB5, DenseNet169 или ResNet50), загружается соответствующая архитектура из tensorflow.keras.applications. weights=None указывает, что модели загружаются без предварительно обученных весов ImageNet. оптимизатор и компилятор для модели.\n",
    "\n",
    "### К базовой модели добавляются следующие слои для классификации:\n",
    "#### GlobalAveragePooling2D(): Уменьшает размерность пространственных признаков до одного вектора, усредняя значения по ширине и высоте.\n",
    "\n",
    "#### Dense (полносвязные слои): Два полносвязных слоя (256 и 64 нейрона) с функциями активации LeakyReLU для нелинейности.\n",
    "\n",
    "#### BatchNormalization(): Нормализует активации для ускорения обучения и повышения стабильности.\n",
    "\n",
    "#### Dropout(): Применяет отсечение нейронов для предотвращения переобучения.\n",
    "\n",
    "#### Финальный Dense(1, activation='sigmoid'): Выходной слой с одним нейроном и sigmoid-активацией для бинарной классификации (выход в диапазоне [0, 1], интерпретируемый как вероятность наличия оползня).\n",
    "\n",
    "#### Используется tf.keras.optimizers.AdamW. Это вариант Adam-оптимизатора с явным учетом весового распада (weight decay), что помогает предотвратить переобучение.\n",
    "\n",
    "### Компиляция модели: Модель компилируется с:\n",
    "\n",
    "#### optimizer: Определенным выше AdamW.\n",
    "\n",
    "#### loss: Пользовательской функцией focal_loss для работы с дисбалансом классов.\n",
    "\n",
    "#### metrics: Пользовательскими метриками f1_m, precision_m, recall_m для оценки производительности."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def create_compiled_model(model_type, input_shape):\n",
    "    base_model = None\n",
    "    if model_type == 'EfficientNetB5':\n",
    "        base_model = EfficientNetB5(weights=None, include_top=False, input_shape=input_shape)\n",
    "    elif model_type == 'DenseNet169':\n",
    "        base_model = DenseNet169(weights=None, include_top=False, input_shape=input_shape)\n",
    "    elif model_type == 'ResNet50':\n",
    "        base_model = ResNet50(weights=None, include_top=False, input_shape=input_shape)\n",
    "\n",
    "    model = Sequential([\n",
    "        base_model,\n",
    "        GlobalAveragePooling2D(),\n",
    "\n",
    "        Dense(256),\n",
    "        BatchNormalization(),\n",
    "        LeakyReLU(alpha=0.01), \n",
    "        Dropout(DROPOUT_RATE_DENSE2),\n",
    "        \n",
    "        Dense(64),\n",
    "        BatchNormalization(),\n",
    "        LeakyReLU(alpha=0.01), \n",
    "        Dropout(DROPOUT_RATE_DENSE3),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    optimizer = tf.keras.optimizers.AdamW(\n",
    "        learning_rate=LEARNING_RATE,\n",
    "        weight_decay=0.01,\n",
    "        beta_1=0.9,\n",
    "        beta_2=0.999\n",
    "    )\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=focal_loss(gamma=2.0, alpha=None),\n",
    "        metrics=[f1_m, precision_m, recall_m]\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "###  Основной цикл обучения ансамбля моделей\n",
    "\n",
    "### Инициализация: Определяются переменные для хранения путей к обученным моделям и метаданных.\n",
    "\n",
    "#### Двойной цикл: Код проходит по каждому model_type (EfficientNetB5, DenseNet169, ResNet50) и для каждого типа выполняет NUM_RUNS_PER_MODEL_TYPE (в данном случае 2) независимых тренировок. Это создает разнообразие в ансамбле.\n",
    "\n",
    "#### Воспроизводимость: На каждом запуске устанавливается новый current_seed для tf.random, np.random и os.environ['PYTHONHASHSEED'], чтобы обеспечить уникальность случайной инициализации и операций, но при этом сохранить возможность воспроизвести каждый отдельный запуск, зная его сид.\n",
    "\n",
    "#### Интеграция с Comet ML:\n",
    "\n",
    "#### Перед началом каждого нового эксперимента создается новый объект comet_ml.Experiment.\n",
    "\n",
    "#### Устанавливается имя эксперимента, которое будет отображаться в панели Comet ML.\n",
    "\n",
    "#### Это позволяет отслеживать метрики, потери и другие данные для каждого запуска модели отдельно.\n",
    "\n",
    "#### Двухфазное обучение (Two-Phase Training): Каждая модель обучается в две фазы:\n",
    "\n",
    "#### Фаза 1: Обучение с BATCH_SIZE_PHASE1=16. Меньшие батчи могут способствовать более быстрой сходимости в начале обучения.\n",
    "\n",
    "#### Фаза 2: Продолжение обучения с BATCH_SIZE_PHASE2=32. Большие батчи могут обеспечить более стабильный градиент и лучшее обобщение на поздних этапах.\n",
    "\n",
    "#### Колбэки (Callbacks): Для обеих фаз обучения используются одинаковые колбэки:\n",
    "\n",
    "#### ModelCheckpoint: Сохраняет лучшую версию модели на основе метрики val_f1_m (F1 на валидационной выборке). save_best_only=True гарантирует сохранение только наилучшей модели.\n",
    "\n",
    "#### EarlyStopping: Останавливает обучение, если val_f1_m не улучшается в течение PATIENCE_EARLY_STOPPING=25 эпох. restore_best_weights=True загружает веса лучшей эпохи после остановки.\n",
    "\n",
    "#### ReduceLROnPlateau: Уменьшает скорость обучения, если val_f1_m не улучшается в течение PATIENCE_REDUCE_LR=6 эпох. Это помогает модели выйти из локальных минимумов.\n",
    "\n",
    "#### Обучение модели: model.fit() запускает процесс обучения, используя созданные генераторы данных и колбэки.\n",
    "\n",
    "#### Сохранение моделей: После завершения обеих фаз обучения (или ранней остановки), лучшая версия каждой обученной модели сохраняется на диск в формате h5.keras или keras в папку ensemble_models_custom. Пути и метаданные моделей записываются для последующего использования в ансамбле.\n",
    "\n",
    "#### Завершение эксперимента Comet ML: experiment.end() закрывает текущий эксперимент в Comet ML, сохраняя все логи."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "input_shape = X_batch.shape[1:] \n",
    "\n",
    "trained_model_paths = [] \n",
    "model_metadata = []      \n",
    "\n",
    "total_runs = len(MODEL_TYPES_FOR_ENSEMBLE) * NUM_RUNS_PER_MODEL_TYPE\n",
    "run_counter = 0\n",
    "\n",
    "for model_type in MODEL_TYPES_FOR_ENSEMBLE:\n",
    "    for i in range(NUM_RUNS_PER_MODEL_TYPE):\n",
    "        run_counter += 1\n",
    "        print(f\"\\n--- Обучение модели {model_type} (Запуск {i+1}/{NUM_RUNS_PER_MODEL_TYPE}) ---\")\n",
    "\n",
    "        current_seed = BASE_RANDOM_SEED + run_counter * 10\n",
    "        tf.random.set_seed(current_seed)\n",
    "        np.random.seed(current_seed)\n",
    "        os.environ['PYTHONHASHSEED'] = str(current_seed)\n",
    "\n",
    "        if 'experiment' in globals() and isinstance(globals()['experiment'], comet_ml.Experiment):\n",
    "            if not globals()['experiment'].ended:\n",
    "                globals()['experiment'].end()\n",
    "        experiment = comet_ml.Experiment(\n",
    "            api_key=COMET_API_KEY,\n",
    "            project_name=\"Classification for Landslide Detection Ensamble\", \n",
    "            auto_output_logging=\"simple\"\n",
    "        )\n",
    "        experiment.flush()\n",
    "        experiment_name = f\"{model_type}_run_{i+1}_seed_{current_seed}\"\n",
    "        experiment.set_name(experiment_name)\n",
    "\n",
    "        print(f\"--- Фаза 1: Обучение с Batch Size {BATCH_SIZE_PHASE1} на {EPOCHS_PHASE1} эпох ---\")\n",
    "        train_gen_phase1 = LandslideDataGenerator(\n",
    "            train_df_split, folder_path, batch_size=BATCH_SIZE_PHASE1, augment=True, shuffle=True)\n",
    "        val_gen_phase1 = LandslideDataGenerator(\n",
    "            val_df_split, folder_path, batch_size=BATCH_SIZE_PHASE1, augment=False, shuffle=False)\n",
    "\n",
    "        model = create_compiled_model(model_type, input_shape)\n",
    "\n",
    "        callbacks_phase1 = [\n",
    "            ModelCheckpoint(\n",
    "                f\"best_model{experiment_name}.h5.keras\",\n",
    "                monitor='val_f1_m',\n",
    "                mode='max',\n",
    "                save_best_only=True,\n",
    "                verbose=3\n",
    "            ),\n",
    "            EarlyStopping(\n",
    "                monitor='val_f1_m', \n",
    "                mode='max',\n",
    "                patience=PATIENCE_EARLY_STOPPING,\n",
    "                verbose=2,\n",
    "                restore_best_weights=True \n",
    "            ),\n",
    "            ReduceLROnPlateau(\n",
    "                monitor='val_f1_m',\n",
    "                mode='max',\n",
    "                factor=0.4,\n",
    "                patience=PATIENCE_REDUCE_LR,\n",
    "                min_lr=MIN_LR,\n",
    "                verbose=2\n",
    "            ),\n",
    "        ]\n",
    "\n",
    "        history_phase1 = model.fit(\n",
    "            train_gen_phase1,\n",
    "            epochs=EPOCHS_PHASE1,\n",
    "            validation_data=val_gen_phase1,\n",
    "            callbacks=callbacks_phase1,\n",
    "        )\n",
    "\n",
    "        print(f\"\\n--- Фаза 2: Продолжение обучения с Batch Size {BATCH_SIZE_PHASE2} на макс. {EPOCHS_PHASE2_MAX} эпох ---\")\n",
    "        train_gen_phase2 = LandslideDataGenerator(\n",
    "            train_df_split, folder_path, batch_size=BATCH_SIZE_PHASE2, augment=True, shuffle=True)\n",
    "        val_gen_phase2 = LandslideDataGenerator(\n",
    "            val_df_split, folder_path, batch_size=BATCH_SIZE_PHASE2, augment=False, shuffle=False)\n",
    "\n",
    "        callbacks_phase2 = [\n",
    "            ModelCheckpoint(\n",
    "                f\"best_model{experiment_name}.h5.keras\",\n",
    "                monitor='val_f1_m',\n",
    "                mode='max',\n",
    "                save_best_only=True,\n",
    "                verbose=3\n",
    "            ),\n",
    "            EarlyStopping(\n",
    "                monitor='val_f1_m',\n",
    "                mode='max',\n",
    "                patience=PATIENCE_EARLY_STOPPING,\n",
    "                restore_best_weights=True,\n",
    "                verbose=2\n",
    "            ),\n",
    "            ReduceLROnPlateau(\n",
    "                monitor='val_f1_m',\n",
    "                mode='max',\n",
    "                factor=0.4,\n",
    "                patience=PATIENCE_REDUCE_LR,\n",
    "                min_lr=MIN_LR,\n",
    "                verbose=2\n",
    "            ),\n",
    "        ]\n",
    "\n",
    "        history_phase2 = model.fit(\n",
    "            train_gen_phase2,\n",
    "            epochs=EPOCHS_PHASE2_MAX,\n",
    "            validation_data=val_gen_phase2,\n",
    "            callbacks=callbacks_phase2,\n",
    "        )\n",
    "\n",
    "        model_save_dir = 'ensemble_models_custom'\n",
    "        os.makedirs(model_save_dir, exist_ok=True)\n",
    "        model_save_path = os.path.join(model_save_dir, f'{experiment_name}.keras')\n",
    "        model.save(model_save_path, save_format='keras')\n",
    "        print(f\"Модель {model_type} (Запуск {i+1}) сохранена в {model_save_path}\")\n",
    "\n",
    "        trained_model_paths.append(model_save_path)\n",
    "        model_metadata.append({'type': model_type, 'seed': current_seed, 'path': model_save_path})\n",
    "\n",
    "        experiment.end()\n",
    "\n",
    "print(\"\\n--- Обучение всех моделей ансамбля завершено ---\")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### График для F1 на валидационной выборке для всех 6 моделей из ансамбля ( по 2 EfficientnetB4, ResNet50, DenseNet169)\n",
    "![ensamble.png](https://github.com/MakarRybkin/Slide_and_seek_classification/raw/master/images_for_report/ensamble.png)\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Получение предсказаний для каждой обученной модели из ансамбля и усреднение ответов"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from tensorflow.keras.models import  load_model\n",
    "all_predictions = []\n",
    "\n",
    "print(\"\\n--- Получение предсказаний каждой обученной моделью ---\")\n",
    "for model_path in trained_model_paths:\n",
    "    print(f\"Загрузка модели: {model_path}\")\n",
    "\n",
    "    model = load_model(model_path,compile=False)\n",
    "\n",
    "    preds = model.predict(val_gen, verbose=1)\n",
    "    all_predictions.append(preds)\n",
    "\n",
    "    tf.keras.backend.clear_session()\n",
    "\n",
    "all_predictions = np.array(all_predictions)\n",
    "\n",
    "ensemble_probabilities = np.mean(all_predictions, axis=0) \n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Определение генератора данных для тестовой выборки (LandslideTestGenerator). Также как и LandslideDataGenerator загружает данные батчами"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class LandslideTestGenerator(Sequence):\n",
    "    def __init__(self, df, data_path, batch_size=32):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.data_path = data_path\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.df) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        batch_df = self.df.iloc[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        batch_X = []\n",
    "\n",
    "        for _, row in batch_df.iterrows():\n",
    "            image_id = row['ID']\n",
    "            image = load_and_normalize_npy_image(image_id, self.data_path)\n",
    "            batch_X.append(image)\n",
    "\n",
    "        return np.array(batch_X)\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Выполнение предсказаний на тестовой выборке и создание файла для отправки"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "test_df = pd.read_csv(test_csv_path)\n",
    "\n",
    "test_gen = LandslideTestGenerator(test_df, test_data_path, batch_size=32)\n",
    "\n",
    "all_test_predictions = []\n",
    "\n",
    "print(\"Making predictions with each trained model on the Test set:\")\n",
    "for model_path in trained_model_paths:\n",
    "    print(f\"Loading model for test predictions: {model_path}\")\n",
    "    \n",
    "    model = load_model(model_path, compile=False)\n",
    "\n",
    "    preds_on_test = model.predict(test_gen, verbose=1)\n",
    "    all_test_predictions.append(preds_on_test)\n",
    "    \n",
    "    tf.keras.backend.clear_session()\n",
    "\n",
    "all_test_predictions = np.array(all_test_predictions)\n",
    "ensemble_test_probabilities = np.mean(all_test_predictions, axis=0)\n",
    "\n",
    "y_test_pred = (ensemble_test_probabilities > 0.5).astype(int)\n",
    "\n",
    "unique, counts = np.unique(y_test_pred, return_counts=True)\n",
    "prediction_counts = dict(zip(unique, counts))\n",
    "print(\"Prediction counts:\", prediction_counts)\n",
    "\n",
    "submission_df = pd.DataFrame({\n",
    "    'ID': test_df['ID'],\n",
    "    'label': y_test_pred.flatten()\n",
    "})\n",
    "submission_df.to_csv(f'Submission_File{experiment_name}.csv', index=False)\n",
    "print(f\"Sample submission file created as 'Submission_File{experiment_name}.csv'.\")\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Заключение\n",
    "### Мы успешно разработали и обучили систему обнаружения оползней, используя комплексный подход к мультиспектральным спутниковым данным Sentinel-1 (SAR) и Sentinel-2 (оптические). Для достижения оптимальных результатов было проведено более 50 экспериментов.\n",
    "### Ключевые методы и достижения:\n",
    "\n",
    "#### Мультимодальная интеграция данных: Эффективно объединили и обработали данные с разных сенсоров. Это позволило модели извлекать комплементарную информацию, что особенно ценно в условиях облачности, когда оптические данные недоступны.\n",
    "\n",
    "#### Борьба с дисбалансом классов: Оползни — редкие события, создающие сильный дисбаланс классов. Мы применили Focal Loss для фокусировки на миноритарном и \"сложном\" классах. Оценка производительности основывалась на F1-мере, Precision и Recall, более релевантных для несбалансированных данных, чем простая точность.\n",
    "\n",
    "#### Аугментация данных: Использование разнообразных техник аугментации (повороты, сдвиги, масштабирование, отражения, изменение яркости/контраста, шум) значительно расширило обучающий набор, повысило устойчивость модели и эффективно предотвратило переобучение.\n",
    "\n",
    "#### Ансамблевое обучение и стратегии оптимизации: Обучили ансамбль из нескольких моделей, включая EfficientNetB5, DenseNet169 и ResNet50. Каждая модель проходила двухфазное обучение с уменьшением размера батча на ранних этапах для ускорения сходимости и увеличением на поздних для стабильности. Использовали Early Stopping для предотвращения переобучения и ReduceLROnPlateau для адаптивного управления скоростью обучения. Усреднение предсказаний ансамбля дало более стабильные и точные итоговые результаты.\n",
    "\n",
    "#### Отслеживание экспериментов: Интеграция с Comet ML обеспечила прозрачное отслеживание, сравнение и воспроизводимость всех экспериментов.\n",
    "\n",
    "### Итоговый результат на текущий момент (20 дней до завершения соревнования):\n",
    "\n",
    "### Благодаря примененным стратегиям, нам удалось достичь F1 = 0.8486. Этот результат позволил занять 47-е место в общем рейтинге соревнования.\n",
    "![current_place.png](https://github.com/MakarRybkin/Slide_and_seek_classification/raw/master/images_for_report/bcurrent_place.png)\n",
    "\n",
    "### Дальнейшие шаги\n",
    "### Я уже активно экспериментирую с гибридными архитектурами CNN + Трансформеры. Цель — объединить сильные стороны CNN (локальное извлечение признаков) и Трансформеров (моделирование глобального контекста) для дальнейшего повышения точности обнаружения оползней.\n",
    "\n"
   ]
  }
 ]
}
